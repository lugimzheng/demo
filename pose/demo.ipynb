{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"demo.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJTNsFUXsgC0","executionInfo":{"status":"ok","timestamp":1607347044367,"user_tz":-480,"elapsed":20734,"user":{"displayName":"lujing zheng","photoUrl":"","userId":"10275059135877011018"}},"outputId":"4aa1ed14-b3f1-4e1e-80fa-38c5bd16a26e"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import os\n","path = '/content/drive/MyDrive/industry/demo/pose'\n","os.chdir(path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"clPAZgQlwXFB","executionInfo":{"status":"ok","timestamp":1607347047864,"user_tz":-480,"elapsed":24210,"user":{"displayName":"lujing zheng","photoUrl":"","userId":"10275059135877011018"}},"outputId":"287712d1-b501-46d4-8629-b29885907d3c"},"source":["!pip install alog"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting alog\n","  Downloading https://files.pythonhosted.org/packages/2d/74/284ce50c11e650ab0c6b19691fe4514e5f6719b6412b6c03c42a1efe0c03/alog-1.1.0-py2.py3-none-any.whl\n","Installing collected packages: alog\n","Successfully installed alog-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOo-U9N_rUkI","executionInfo":{"status":"ok","timestamp":1607347067436,"user_tz":-480,"elapsed":18232,"user":{"displayName":"lujing zheng","photoUrl":"","userId":"10275059135877011018"}},"outputId":"badf9b40-8c70-4f64-a324-18e40ea026e2"},"source":["# coding: utf-8\n","\n","import numpy as np\n","import torch\n","import os\n","import time\n","\n","# import matplotlib\n","# matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","%matplotlib inline  \n","\n","from networks import *\n","from network import CoordRegressionNetwork\n","from torch.utils.data import DataLoader\n","from dataset_factory import DatasetFactory, ROOT_DIR\n","import multiprocessing\n","from tqdm import tqdm\n","\n","# gpu setting\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","torch.backends.cudnn.enabled = True\n","device = torch.device(\"cuda\" if True else \"cpu\")\n","num_threads = multiprocessing.cpu_count()\n","print(\"GPU NUM: %d, Thread NUM: %d\"%(torch.cuda.device_count(),num_threads))\n","\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":3,"outputs":[{"output_type":"stream","text":["GPU NUM: 1, Thread NUM: 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D1H7JufGrUkL"},"source":["# load pretrain model\n","# modelpath = \"./models/resnet18_224_new_best.t7\"\n","# modelname = \"shufflenetv2\"\n","modelname = \"resnet18\"\n","modelpath = \"./models/%s_224_adam_best.t7\"%(modelname)\n","inputsize = 224\n","net = CoordRegressionNetwork(n_locations=16, backbone=modelname).to(device)\n","\n","train_dataset = DatasetFactory.get_train_dataset(\"resnet\", inputsize)\n","train_dataloader = DataLoader(train_dataset, batch_size=256,\n","                        shuffle=True, num_workers = num_threads)\n","\n","test_dataset = DatasetFactory.get_test_dataset(\"resnet\", inputsize)\n","test_dataloader = DataLoader(test_dataset, batch_size=256,\n","                        shuffle=False, num_workers = num_threads)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":863},"id":"8YPxipGLrUkL","executionInfo":{"status":"error","timestamp":1607236733569,"user_tz":-480,"elapsed":3349,"user":{"displayName":"lujing zheng","photoUrl":"","userId":"10275059135877011018"}},"outputId":"1e8f9db0-3699-46d3-e898-5cb8322fac0c"},"source":["from dataloader import display_pose\n","plt.figure(figsize=(20,140))\n","\n","with torch.no_grad():  \n","    net.load_state_dict(torch.load(modelpath))\n","    net = net.eval()\n","\n","    for i_batch, sample_batched in enumerate(tqdm(test_dataloader)):\n","\n","        images = sample_batched['image'].to(device)\n","        poses = sample_batched['pose'].to(device)\n","        \n","        t0 = time.clock()\n","        coords, heatmaps = net(images)\n","        t1 = time.clock()\n","        print('average forward seconds=%f s| fps=%d'%((t1-t0),int(1/((t1-t0)))))\n","        \n","        for ids in range(40,60):\n","            display_pose(images[ids][:3,:,:],coords[ids],ids)\n","        plt.show()\n","        break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-be5b9d50dec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/drive/MyDrive/industry/MobilePose-pytorch-master/dataloader.py\", line 195, in __getitem__\n    image = io.imread(img_path)\n  File \"/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py\", line 48, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n  File \"/usr/local/lib/python3.6/dist-packages/skimage/io/manage_plugins.py\", line 210, in call_plugin\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/skimage/io/_plugins/imageio_plugin.py\", line 10, in imread\n    return np.asarray(imageio_imread(*args, **kwargs))\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\", line 221, in imread\n    reader = read(uri, format, \"i\", **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\", line 130, in get_reader\n    request = Request(uri, \"r\" + mode, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/request.py\", line 125, in __init__\n    self._parse_uri(uri)\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/request.py\", line 273, in _parse_uri\n    raise FileNotFoundError(\"No such file: '%s'\" % fn)\nFileNotFoundError: No such file: '/content/drive/My Drive/industry/MobilePose-pytorch-master/pose_dataset/mpii/images/093311333.jpg'\n"]}]},{"cell_type":"code","metadata":{"id":"y8TJrceErUkM"},"source":["plt.imshow(heatmaps[0, 8].data.cpu().numpy())\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Der3un6YrUkM"},"source":["from torchsummary import summary\n","import torch\n","from networks import *\n","from networks.senet import se_resnet\n","from torchvision.models import resnet18\n","import os\n","device = torch.device(\"cuda\" if True else \"cpu\")\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n","\n","# model = se_resnet.senet18_ed().to(device)\n","model = resnet18_ed().to(device)\n","# model = resnet18().to(device)\n","# model = ShuffleNetV2.shufflenetv2_ed(width_mult=1.0).to(device)\n","# model = MobileNetV2.mobilenetv2_ed(width_mult=1.0).to(device)\n","# model = nn.Sequential(*(list(model.children())[:-3]))\n","# model = squeezenet1_1().to(device)\n","summary(model, input_size=(3, 224, 224))\n","# print(list(model.children())[:-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m8EwIKszrUkM"},"source":["from thop import profile\n","from torchsummary import summary\n","import torch\n","from networks import *\n","from torchvision.models import resnet18\n","\n","import os\n","device = torch.device(\"cuda\" if False else \"cpu\")\n","\n","model = resnet.resnet18_ed().to(device)\n","# model = UNet().to(device)\n","# model = resnet18().to(device)\n","# model = ShuffleNetV2.shufflenetv2_ed(width_mult=1.0).to(device)\n","# model = MobileNetV2.mobilenetv2_ed(width_mult=1.0).to(device)\n","# model = squeezenet1_1().to(device)\n","flops, params = profile(model, input_size=(1, 3, 224,224))\n","print(params/(1024**2), flops/(1024**3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ZqHLYF3rUkM","outputId":"4374883f-bd9f-47e7-8fba-1ca8adfb89fb"},"source":["import json\n","from tqdm import tqdm\n","j_path=\"/home/yuliang/code/AlphaPose-pytorch/train_sppe/data/coco/person_keypoints_val2017.json\"\n","txt_path = \"/home/yuliang/code/AlphaPose-pytorch/train_sppe/data/coco/list/trainval.txt\"\n","with open(j_path, 'rb') as j:\n","    j_data = json.load(j)\n","    with open(txt_path, 'wb') as t:\n","        for img_anno in tqdm(j_data['annotations']):\n","            t.write((\"%012d\\n\"%img_anno['image_id']).encode())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/11004 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 11004/11004 [00:00<00:00, 206496.90it/s]\u001b[A"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"j_mutjKZrUkM","outputId":"4b05de78-c4fd-4208-d7fe-a01e4ffd5d7d"},"source":["j_data['annotations'][134]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'area': 1812.626,\n"," 'bbox': [385.79, 233.83, 28.04, 97.07],\n"," 'category_id': 1,\n"," 'id': 229636,\n"," 'image_id': 577932,\n"," 'iscrowd': 0,\n"," 'keypoints': [402,\n","  243,\n","  2,\n","  403,\n","  241,\n","  2,\n","  399,\n","  240,\n","  2,\n","  0,\n","  0,\n","  0,\n","  395,\n","  242,\n","  2,\n","  406,\n","  253,\n","  2,\n","  392,\n","  255,\n","  2,\n","  414,\n","  262,\n","  1,\n","  392,\n","  271,\n","  2,\n","  409,\n","  255,\n","  2,\n","  394,\n","  282,\n","  2,\n","  407,\n","  283,\n","  2,\n","  398,\n","  284,\n","  2,\n","  403,\n","  306,\n","  2,\n","  397,\n","  305,\n","  2,\n","  401,\n","  323,\n","  2,\n","  395,\n","  322,\n","  2],\n"," 'num_keypoints': 16,\n"," 'segmentation': [[389.3,\n","   330.55,\n","   390.35,\n","   300.76,\n","   389.65,\n","   294.1,\n","   388.6,\n","   274.13,\n","   385.79,\n","   259.76,\n","   386.14,\n","   254.86,\n","   390.7,\n","   248.9,\n","   391.75,\n","   246.45,\n","   395.25,\n","   235.23,\n","   402.96,\n","   233.83,\n","   407.17,\n","   245.74,\n","   406.12,\n","   250.3,\n","   413.83,\n","   255.56,\n","   412.07,\n","   262.91,\n","   411.72,\n","   293.05,\n","   410.67,\n","   294.45,\n","   407.17,\n","   295.85,\n","   407.87,\n","   302.16,\n","   405.06,\n","   308.47,\n","   403.66,\n","   313.73,\n","   401.91,\n","   318.98,\n","   405.77,\n","   323.19,\n","   408.57,\n","   328.79,\n","   388.95,\n","   330.9]]}"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"dYWO16K0rUkM"},"source":["import numpy as np\n","\n","def create_heatmap(self, size, poses, sigma):\n","        \n","    x = np.arange(0, size)\n","    y = np.arange(0, size)\n","    x, y = np.meshgrid(x, y)\n","    guass_heatmap = np.zeros([poses.shape[1], size, size])\n","    sigma /= size\n","\n","    for pose in poses:\n","        for idx,(x0,y0) in enumerate(pose):\n","            guass_heatmap[idx] += np.exp(-((x*1.0/size-x0)**2+(y*1.0/size-y0)**2)/(2.0*sigma**2))\n","\n","    return guass_heatmap"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jphKW-HrrUkN"},"source":["heatmap = self.create_heatmap(image.shape[2], label[:,4:].reshape(-1,17,3)[:,:,:2], 1.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPx8ARC-rUkN"},"source":["import json\n","from tqdm import tqdm\n","j_path=\"/home/yuliang/code/AlphaPose-pytorch/train_sppe/data/coco/person_keypoints_val2017.json\"\n","\n","with open(j_path, 'rb') as j:\n","    j_data = json.load(j)\n","    for img_anno in tqdm(j_data['annotations']):\n","        \n","        binary_path = \"/home/yuliang/code/Deeplab-Seg/Deeplab/datasets/coco/PoseHeatmap/binary\"\n","        guass_path = \"/home/yuliang/code/Deeplab-Seg/Deeplab/datasets/coco/PoseHeatmap/guass\"\n","        \n","        t.write((\"%012d\\n\"%img_anno['image_id']).encode())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJBJype9rUkN"},"source":["import pycocotools"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdArMsSwrUkN"},"source":[""],"execution_count":null,"outputs":[]}]}